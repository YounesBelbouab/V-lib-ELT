# ğŸš² Projet Data Pipeline VÃ©lib' - GCP & DBT

Ce projet a pour but de rÃ©cupÃ©rer les donnÃ©es des stations VÃ©libâ€™ via lâ€™API officielle, de les stocker sur Google Cloud Platform (GCP) puis de les transformer et modÃ©liser via une pipeline DBT (Data Build Tool).

## ğŸ“Œ Objectifs

- Collecter les donnÃ©es en temps rÃ©el sur les stations VÃ©libâ€™ (disponibilitÃ©, Ã©tat, etc.)
- Stocker ces donnÃ©es dans un data lake sur GCP (BigQuery ou Cloud Storage)
- Construire une pipeline de traitement et de modÃ©lisation des donnÃ©es avec DBT
- PrÃ©parer des donnÃ©es prÃªtes Ã  lâ€™analyse ou Ã  la visualisation

## ğŸ› ï¸ Stack technique

- **Langage :** Python  
- **Sources de donnÃ©es :** API VÃ©libâ€™ MÃ©tropole  
- **Cloud :** Google Cloud Platform (GCP)  
  - Cloud Storage (optionnel)  
  - BigQuery  
- **Orchestration / ModÃ©lisation :** DBT (Data Build Tool)

## ğŸš€ Ã‰tapes du pipeline

1. **RÃ©cupÃ©ration des donnÃ©es**  
   Script Python pour appeler lâ€™API VÃ©libâ€™ et collecter les donnÃ©es au format JSON.

2. **Envoi sur GCP**  
   Transformation et chargement des donnÃ©es vers BigQuery (ou via Cloud Storage).

3. **Transformation avec DBT**  
   ModÃ¨les DBT pour nettoyer, enrichir et structurer les donnÃ©es.

4. **Visualisation des donnÃ©es**  
   CrÃ©ation de dashboards via Looker Studio ou autre outil BI.

## â–¶ï¸ ExÃ©cution

1. **Installer les dÃ©pendances Python**  
   ```bash
   pip install -r requirements.txt

![alt text](images\relationel bdd.png)